{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.992707086099924,
  "eval_steps": 500,
  "global_step": 5500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05442473059758354,
      "grad_norm": 38.2878532409668,
      "learning_rate": 1.9666303953572724e-05,
      "loss": 4.2498,
      "step": 100
    },
    {
      "epoch": 0.10884946119516709,
      "grad_norm": 30.668384552001953,
      "learning_rate": 1.9303590859630033e-05,
      "loss": 3.9379,
      "step": 200
    },
    {
      "epoch": 0.16327419179275063,
      "grad_norm": 28.459415435791016,
      "learning_rate": 1.8940877765687343e-05,
      "loss": 3.6548,
      "step": 300
    },
    {
      "epoch": 0.21769892239033417,
      "grad_norm": 34.09061813354492,
      "learning_rate": 1.8578164671744652e-05,
      "loss": 3.4832,
      "step": 400
    },
    {
      "epoch": 0.2721236529879177,
      "grad_norm": 29.43716812133789,
      "learning_rate": 1.8215451577801958e-05,
      "loss": 3.3704,
      "step": 500
    },
    {
      "epoch": 0.2721236529879177,
      "eval_loss": 3.3295319080352783,
      "eval_runtime": 50.9056,
      "eval_samples_per_second": 76.003,
      "eval_steps_per_second": 9.508,
      "step": 500
    },
    {
      "epoch": 0.32654838358550126,
      "grad_norm": 27.577680587768555,
      "learning_rate": 1.785273848385927e-05,
      "loss": 3.2979,
      "step": 600
    },
    {
      "epoch": 0.38097311418308477,
      "grad_norm": 27.141841888427734,
      "learning_rate": 1.749002538991658e-05,
      "loss": 3.2161,
      "step": 700
    },
    {
      "epoch": 0.43539784478066834,
      "grad_norm": 30.02587127685547,
      "learning_rate": 1.7127312295973885e-05,
      "loss": 3.1703,
      "step": 800
    },
    {
      "epoch": 0.48982257537825186,
      "grad_norm": 30.467905044555664,
      "learning_rate": 1.6764599202031194e-05,
      "loss": 3.126,
      "step": 900
    },
    {
      "epoch": 0.5442473059758354,
      "grad_norm": 30.034990310668945,
      "learning_rate": 1.6401886108088504e-05,
      "loss": 3.0927,
      "step": 1000
    },
    {
      "epoch": 0.5442473059758354,
      "eval_loss": 3.1516761779785156,
      "eval_runtime": 50.8166,
      "eval_samples_per_second": 76.137,
      "eval_steps_per_second": 9.524,
      "step": 1000
    },
    {
      "epoch": 0.5986720365734189,
      "grad_norm": 28.65852165222168,
      "learning_rate": 1.6039173014145813e-05,
      "loss": 3.0642,
      "step": 1100
    },
    {
      "epoch": 0.6530967671710025,
      "grad_norm": 23.946928024291992,
      "learning_rate": 1.567645992020312e-05,
      "loss": 3.0211,
      "step": 1200
    },
    {
      "epoch": 0.7075214977685861,
      "grad_norm": 726.7405395507812,
      "learning_rate": 1.5313746826260428e-05,
      "loss": 3.2335,
      "step": 1300
    },
    {
      "epoch": 0.7619462283661695,
      "grad_norm": 173950.03125,
      "learning_rate": 1.496191512513602e-05,
      "loss": 3.2082,
      "step": 1400
    },
    {
      "epoch": 0.8163709589637531,
      "grad_norm": 88121.15625,
      "learning_rate": 1.4613710554951035e-05,
      "loss": 3.3486,
      "step": 1500
    },
    {
      "epoch": 0.8163709589637531,
      "eval_loss": 3.3769829273223877,
      "eval_runtime": 50.8164,
      "eval_samples_per_second": 76.137,
      "eval_steps_per_second": 9.524,
      "step": 1500
    },
    {
      "epoch": 0.8707956895613367,
      "grad_norm": 1338844.0,
      "learning_rate": 1.4258251722887197e-05,
      "loss": 5.5678,
      "step": 1600
    },
    {
      "epoch": 0.9252204201589203,
      "grad_norm": 122.6900405883789,
      "learning_rate": 1.3895538628944508e-05,
      "loss": 5.6148,
      "step": 1700
    },
    {
      "epoch": 0.9796451507565037,
      "grad_norm": 58.09225082397461,
      "learning_rate": 1.3532825535001814e-05,
      "loss": 3.7042,
      "step": 1800
    },
    {
      "epoch": 1.0337433329705017,
      "grad_norm": 12059.2666015625,
      "learning_rate": 1.3170112441059125e-05,
      "loss": 4.7114,
      "step": 1900
    },
    {
      "epoch": 1.0881680635680853,
      "grad_norm": 6512.20849609375,
      "learning_rate": 1.2807399347116432e-05,
      "loss": 5.4175,
      "step": 2000
    },
    {
      "epoch": 1.0881680635680853,
      "eval_loss": 7.727628707885742,
      "eval_runtime": 50.7636,
      "eval_samples_per_second": 76.216,
      "eval_steps_per_second": 9.534,
      "step": 2000
    },
    {
      "epoch": 1.1425927941656688,
      "grad_norm": 237202.25,
      "learning_rate": 1.2444686253173741e-05,
      "loss": 8.0643,
      "step": 2100
    },
    {
      "epoch": 1.1970175247632524,
      "grad_norm": 26261260.0,
      "learning_rate": 1.2085600290170475e-05,
      "loss": 8.061,
      "step": 2200
    },
    {
      "epoch": 1.251442255360836,
      "grad_norm": 122.6884536743164,
      "learning_rate": 1.1748277112803775e-05,
      "loss": 9.8999,
      "step": 2300
    },
    {
      "epoch": 1.3058669859584195,
      "grad_norm": 99.3603744506836,
      "learning_rate": 1.1385564018861082e-05,
      "loss": 15.483,
      "step": 2400
    },
    {
      "epoch": 1.3602917165560031,
      "grad_norm": 78901.53125,
      "learning_rate": 1.1022850924918391e-05,
      "loss": 22.2264,
      "step": 2500
    },
    {
      "epoch": 1.3602917165560031,
      "eval_loss": 24.177350997924805,
      "eval_runtime": 50.7389,
      "eval_samples_per_second": 76.253,
      "eval_steps_per_second": 9.539,
      "step": 2500
    },
    {
      "epoch": 1.4147164471535865,
      "grad_norm": 119.30807495117188,
      "learning_rate": 1.0660137830975699e-05,
      "loss": 26.6757,
      "step": 2600
    },
    {
      "epoch": 1.4691411777511703,
      "grad_norm": 121.05438995361328,
      "learning_rate": 1.0297424737033008e-05,
      "loss": 30.9543,
      "step": 2700
    },
    {
      "epoch": 1.5235659083487536,
      "grad_norm": 133.7433319091797,
      "learning_rate": 9.934711643090317e-06,
      "loss": 35.6054,
      "step": 2800
    },
    {
      "epoch": 1.5779906389463372,
      "grad_norm": 129.40542602539062,
      "learning_rate": 9.571998549147625e-06,
      "loss": 39.5792,
      "step": 2900
    },
    {
      "epoch": 1.6324153695439207,
      "grad_norm": 129.72055053710938,
      "learning_rate": 9.209285455204934e-06,
      "loss": 42.9991,
      "step": 3000
    },
    {
      "epoch": 1.6324153695439207,
      "eval_loss": 44.55278396606445,
      "eval_runtime": 50.7343,
      "eval_samples_per_second": 76.26,
      "eval_steps_per_second": 9.54,
      "step": 3000
    },
    {
      "epoch": 1.6868401001415043,
      "grad_norm": 134.84979248046875,
      "learning_rate": 8.846572361262242e-06,
      "loss": 46.0604,
      "step": 3100
    },
    {
      "epoch": 1.7412648307390879,
      "grad_norm": 138.57351684570312,
      "learning_rate": 8.48385926731955e-06,
      "loss": 48.8888,
      "step": 3200
    },
    {
      "epoch": 1.7956895613366712,
      "grad_norm": 134.08152770996094,
      "learning_rate": 8.12114617337686e-06,
      "loss": 51.6618,
      "step": 3300
    },
    {
      "epoch": 1.850114291934255,
      "grad_norm": 115.5047607421875,
      "learning_rate": 7.758433079434167e-06,
      "loss": 53.7952,
      "step": 3400
    },
    {
      "epoch": 1.9045390225318384,
      "grad_norm": 42210.96875,
      "learning_rate": 7.395719985491477e-06,
      "loss": 55.9291,
      "step": 3500
    },
    {
      "epoch": 1.9045390225318384,
      "eval_loss": 56.49250793457031,
      "eval_runtime": 50.7508,
      "eval_samples_per_second": 76.235,
      "eval_steps_per_second": 9.537,
      "step": 3500
    },
    {
      "epoch": 1.9589637531294222,
      "grad_norm": 1823.931640625,
      "learning_rate": 7.033006891548786e-06,
      "loss": 57.6801,
      "step": 3600
    },
    {
      "epoch": 2.01306193534342,
      "grad_norm": 108.32376861572266,
      "learning_rate": 6.670293797606094e-06,
      "loss": 58.8866,
      "step": 3700
    },
    {
      "epoch": 2.0674866659410034,
      "grad_norm": 141.06016540527344,
      "learning_rate": 6.3075807036634025e-06,
      "loss": 59.834,
      "step": 3800
    },
    {
      "epoch": 2.121911396538587,
      "grad_norm": 136.9415283203125,
      "learning_rate": 5.944867609720712e-06,
      "loss": 61.4782,
      "step": 3900
    },
    {
      "epoch": 2.1763361271361705,
      "grad_norm": 129.4517364501953,
      "learning_rate": 5.58215451577802e-06,
      "loss": 62.2998,
      "step": 4000
    },
    {
      "epoch": 2.1763361271361705,
      "eval_loss": 62.638954162597656,
      "eval_runtime": 50.7189,
      "eval_samples_per_second": 76.283,
      "eval_steps_per_second": 9.543,
      "step": 4000
    },
    {
      "epoch": 2.2307608577337543,
      "grad_norm": 143.52577209472656,
      "learning_rate": 5.219441421835328e-06,
      "loss": 63.7211,
      "step": 4100
    },
    {
      "epoch": 2.2851855883313377,
      "grad_norm": 140.76058959960938,
      "learning_rate": 4.856728327892638e-06,
      "loss": 64.4527,
      "step": 4200
    },
    {
      "epoch": 2.3396103189289215,
      "grad_norm": 5670.6044921875,
      "learning_rate": 4.494015233949946e-06,
      "loss": 64.6423,
      "step": 4300
    },
    {
      "epoch": 2.394035049526505,
      "grad_norm": 138.58372497558594,
      "learning_rate": 4.131302140007254e-06,
      "loss": 63.9367,
      "step": 4400
    },
    {
      "epoch": 2.4484597801240886,
      "grad_norm": 136.58755493164062,
      "learning_rate": 3.768589046064563e-06,
      "loss": 63.9082,
      "step": 4500
    },
    {
      "epoch": 2.4484597801240886,
      "eval_loss": 63.90351867675781,
      "eval_runtime": 50.7258,
      "eval_samples_per_second": 76.273,
      "eval_steps_per_second": 9.541,
      "step": 4500
    },
    {
      "epoch": 2.502884510721672,
      "grad_norm": 138.24142456054688,
      "learning_rate": 3.4058759521218722e-06,
      "loss": 64.268,
      "step": 4600
    },
    {
      "epoch": 2.5573092413192553,
      "grad_norm": 141.43553161621094,
      "learning_rate": 3.0431628581791806e-06,
      "loss": 64.8499,
      "step": 4700
    },
    {
      "epoch": 2.611733971916839,
      "grad_norm": 100.52764892578125,
      "learning_rate": 2.680449764236489e-06,
      "loss": 65.4191,
      "step": 4800
    },
    {
      "epoch": 2.6661587025144224,
      "grad_norm": 131.1272430419922,
      "learning_rate": 2.3177366702937977e-06,
      "loss": 65.3277,
      "step": 4900
    },
    {
      "epoch": 2.7205834331120062,
      "grad_norm": 139.69737243652344,
      "learning_rate": 1.9550235763511065e-06,
      "loss": 66.0082,
      "step": 5000
    },
    {
      "epoch": 2.7205834331120062,
      "eval_loss": 65.8045883178711,
      "eval_runtime": 50.7436,
      "eval_samples_per_second": 76.246,
      "eval_steps_per_second": 9.538,
      "step": 5000
    },
    {
      "epoch": 2.7750081637095896,
      "grad_norm": 98.92379760742188,
      "learning_rate": 1.592310482408415e-06,
      "loss": 66.0784,
      "step": 5100
    },
    {
      "epoch": 2.829432894307173,
      "grad_norm": 134.62779235839844,
      "learning_rate": 1.2295973884657238e-06,
      "loss": 66.1657,
      "step": 5200
    },
    {
      "epoch": 2.8838576249047567,
      "grad_norm": 739.4114379882812,
      "learning_rate": 8.668842945230324e-07,
      "loss": 66.4829,
      "step": 5300
    },
    {
      "epoch": 2.9382823555023405,
      "grad_norm": 433.3081970214844,
      "learning_rate": 5.04171200580341e-07,
      "loss": 66.5524,
      "step": 5400
    },
    {
      "epoch": 2.992707086099924,
      "grad_norm": 362.9814147949219,
      "learning_rate": 1.4145810663764961e-07,
      "loss": 66.6455,
      "step": 5500
    },
    {
      "epoch": 2.992707086099924,
      "eval_loss": 66.44773864746094,
      "eval_runtime": 50.75,
      "eval_samples_per_second": 76.237,
      "eval_steps_per_second": 9.537,
      "step": 5500
    }
  ],
  "logging_steps": 100,
  "max_steps": 5514,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6961787396698112e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
