{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.992707086099924,
  "eval_steps": 500,
  "global_step": 5500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05442473059758354,
      "grad_norm": 211.00381469726562,
      "learning_rate": 1.9669931084512154e-05,
      "loss": 65.0953,
      "step": 100
    },
    {
      "epoch": 0.10884946119516709,
      "grad_norm": 192.26010131835938,
      "learning_rate": 1.930721799056946e-05,
      "loss": 46.1547,
      "step": 200
    },
    {
      "epoch": 0.16327419179275063,
      "grad_norm": 64.80204010009766,
      "learning_rate": 1.894450489662677e-05,
      "loss": 43.4422,
      "step": 300
    },
    {
      "epoch": 0.21769892239033417,
      "grad_norm": 76.99211120605469,
      "learning_rate": 1.858179180268408e-05,
      "loss": 42.3372,
      "step": 400
    },
    {
      "epoch": 0.2721236529879177,
      "grad_norm": 55.15657424926758,
      "learning_rate": 1.8219078708741388e-05,
      "loss": 40.9385,
      "step": 500
    },
    {
      "epoch": 0.2721236529879177,
      "eval_loss": 3.950230836868286,
      "eval_runtime": 10.5775,
      "eval_samples_per_second": 365.776,
      "eval_steps_per_second": 45.757,
      "step": 500
    },
    {
      "epoch": 0.32654838358550126,
      "grad_norm": 50.581478118896484,
      "learning_rate": 1.7856365614798697e-05,
      "loss": 40.8158,
      "step": 600
    },
    {
      "epoch": 0.38097311418308477,
      "grad_norm": 108.9596939086914,
      "learning_rate": 1.7493652520856003e-05,
      "loss": 40.127,
      "step": 700
    },
    {
      "epoch": 0.43539784478066834,
      "grad_norm": 52.423736572265625,
      "learning_rate": 1.7130939426913312e-05,
      "loss": 39.2187,
      "step": 800
    },
    {
      "epoch": 0.48982257537825186,
      "grad_norm": 52.48405075073242,
      "learning_rate": 1.676822633297062e-05,
      "loss": 39.6311,
      "step": 900
    },
    {
      "epoch": 0.5442473059758354,
      "grad_norm": 41.61742401123047,
      "learning_rate": 1.640551323902793e-05,
      "loss": 38.9069,
      "step": 1000
    },
    {
      "epoch": 0.5442473059758354,
      "eval_loss": 3.7690839767456055,
      "eval_runtime": 10.579,
      "eval_samples_per_second": 365.726,
      "eval_steps_per_second": 45.751,
      "step": 1000
    },
    {
      "epoch": 0.5986720365734189,
      "grad_norm": 92.20974731445312,
      "learning_rate": 1.604280014508524e-05,
      "loss": 38.8787,
      "step": 1100
    },
    {
      "epoch": 0.6530967671710025,
      "grad_norm": 56.211917877197266,
      "learning_rate": 1.568008705114255e-05,
      "loss": 38.1556,
      "step": 1200
    },
    {
      "epoch": 0.7075214977685861,
      "grad_norm": 85.90802001953125,
      "learning_rate": 1.5317373957199858e-05,
      "loss": 38.233,
      "step": 1300
    },
    {
      "epoch": 0.7619462283661695,
      "grad_norm": 61.082794189453125,
      "learning_rate": 1.4954660863257164e-05,
      "loss": 37.6166,
      "step": 1400
    },
    {
      "epoch": 0.8163709589637531,
      "grad_norm": 56.434200286865234,
      "learning_rate": 1.4591947769314474e-05,
      "loss": 37.4422,
      "step": 1500
    },
    {
      "epoch": 0.8163709589637531,
      "eval_loss": 3.696981906890869,
      "eval_runtime": 10.5831,
      "eval_samples_per_second": 365.582,
      "eval_steps_per_second": 45.733,
      "step": 1500
    },
    {
      "epoch": 0.8707956895613367,
      "grad_norm": 54.529117584228516,
      "learning_rate": 1.4229234675371782e-05,
      "loss": 37.6311,
      "step": 1600
    },
    {
      "epoch": 0.9252204201589203,
      "grad_norm": 53.73786544799805,
      "learning_rate": 1.3866521581429091e-05,
      "loss": 37.4222,
      "step": 1700
    },
    {
      "epoch": 0.9796451507565037,
      "grad_norm": 58.41358947753906,
      "learning_rate": 1.3503808487486399e-05,
      "loss": 36.7577,
      "step": 1800
    },
    {
      "epoch": 1.0337433329705017,
      "grad_norm": 56.79832458496094,
      "learning_rate": 1.3141095393543708e-05,
      "loss": 36.7567,
      "step": 1900
    },
    {
      "epoch": 1.0881680635680853,
      "grad_norm": 44.22560501098633,
      "learning_rate": 1.2778382299601017e-05,
      "loss": 37.0849,
      "step": 2000
    },
    {
      "epoch": 1.0881680635680853,
      "eval_loss": 3.6504764556884766,
      "eval_runtime": 10.5833,
      "eval_samples_per_second": 365.576,
      "eval_steps_per_second": 45.732,
      "step": 2000
    },
    {
      "epoch": 1.1425927941656688,
      "grad_norm": 44.91073989868164,
      "learning_rate": 1.2415669205658325e-05,
      "loss": 36.4443,
      "step": 2100
    },
    {
      "epoch": 1.1970175247632524,
      "grad_norm": 37.90470886230469,
      "learning_rate": 1.2052956111715635e-05,
      "loss": 37.06,
      "step": 2200
    },
    {
      "epoch": 1.251442255360836,
      "grad_norm": 59.470237731933594,
      "learning_rate": 1.1690243017772941e-05,
      "loss": 36.1986,
      "step": 2300
    },
    {
      "epoch": 1.3058669859584195,
      "grad_norm": 73.51252746582031,
      "learning_rate": 1.1327529923830252e-05,
      "loss": 36.5075,
      "step": 2400
    },
    {
      "epoch": 1.3602917165560031,
      "grad_norm": 60.5399055480957,
      "learning_rate": 1.096481682988756e-05,
      "loss": 36.466,
      "step": 2500
    },
    {
      "epoch": 1.3602917165560031,
      "eval_loss": 3.5952413082122803,
      "eval_runtime": 10.5796,
      "eval_samples_per_second": 365.705,
      "eval_steps_per_second": 45.749,
      "step": 2500
    },
    {
      "epoch": 1.4147164471535865,
      "grad_norm": 46.51451873779297,
      "learning_rate": 1.0602103735944869e-05,
      "loss": 36.3856,
      "step": 2600
    },
    {
      "epoch": 1.4691411777511703,
      "grad_norm": 87.79716491699219,
      "learning_rate": 1.0239390642002176e-05,
      "loss": 36.2277,
      "step": 2700
    },
    {
      "epoch": 1.5235659083487536,
      "grad_norm": 231.4840087890625,
      "learning_rate": 9.876677548059486e-06,
      "loss": 35.9917,
      "step": 2800
    },
    {
      "epoch": 1.5779906389463372,
      "grad_norm": 57.706787109375,
      "learning_rate": 9.513964454116795e-06,
      "loss": 36.0234,
      "step": 2900
    },
    {
      "epoch": 1.6324153695439207,
      "grad_norm": 47.55577087402344,
      "learning_rate": 9.151251360174102e-06,
      "loss": 35.7923,
      "step": 3000
    },
    {
      "epoch": 1.6324153695439207,
      "eval_loss": 3.582899570465088,
      "eval_runtime": 10.5817,
      "eval_samples_per_second": 365.632,
      "eval_steps_per_second": 45.739,
      "step": 3000
    },
    {
      "epoch": 1.6868401001415043,
      "grad_norm": 78.74972534179688,
      "learning_rate": 8.788538266231411e-06,
      "loss": 35.8386,
      "step": 3100
    },
    {
      "epoch": 1.7412648307390879,
      "grad_norm": 78.65618896484375,
      "learning_rate": 8.42582517228872e-06,
      "loss": 35.84,
      "step": 3200
    },
    {
      "epoch": 1.7956895613366712,
      "grad_norm": 164.90011596679688,
      "learning_rate": 8.06311207834603e-06,
      "loss": 35.8265,
      "step": 3300
    },
    {
      "epoch": 1.850114291934255,
      "grad_norm": 55.530540466308594,
      "learning_rate": 7.700398984403337e-06,
      "loss": 35.7645,
      "step": 3400
    },
    {
      "epoch": 1.9045390225318384,
      "grad_norm": 50.26460647583008,
      "learning_rate": 7.3376858904606465e-06,
      "loss": 36.2261,
      "step": 3500
    },
    {
      "epoch": 1.9045390225318384,
      "eval_loss": 3.5387485027313232,
      "eval_runtime": 10.5922,
      "eval_samples_per_second": 365.269,
      "eval_steps_per_second": 45.694,
      "step": 3500
    },
    {
      "epoch": 1.9589637531294222,
      "grad_norm": 50.39349365234375,
      "learning_rate": 6.974972796517955e-06,
      "loss": 35.8425,
      "step": 3600
    },
    {
      "epoch": 2.01306193534342,
      "grad_norm": 74.74311828613281,
      "learning_rate": 6.612259702575263e-06,
      "loss": 36.2969,
      "step": 3700
    },
    {
      "epoch": 2.0674866659410034,
      "grad_norm": 47.866275787353516,
      "learning_rate": 6.2495466086325715e-06,
      "loss": 35.5643,
      "step": 3800
    },
    {
      "epoch": 2.121911396538587,
      "grad_norm": 47.921905517578125,
      "learning_rate": 5.88683351468988e-06,
      "loss": 35.67,
      "step": 3900
    },
    {
      "epoch": 2.1763361271361705,
      "grad_norm": 40.21951675415039,
      "learning_rate": 5.52412042074719e-06,
      "loss": 35.6825,
      "step": 4000
    },
    {
      "epoch": 2.1763361271361705,
      "eval_loss": 3.505389928817749,
      "eval_runtime": 10.5743,
      "eval_samples_per_second": 365.887,
      "eval_steps_per_second": 45.771,
      "step": 4000
    },
    {
      "epoch": 2.2307608577337543,
      "grad_norm": 74.73465728759766,
      "learning_rate": 5.161407326804498e-06,
      "loss": 35.3748,
      "step": 4100
    },
    {
      "epoch": 2.2851855883313377,
      "grad_norm": 63.874656677246094,
      "learning_rate": 4.798694232861807e-06,
      "loss": 35.6584,
      "step": 4200
    },
    {
      "epoch": 2.3396103189289215,
      "grad_norm": 46.9151725769043,
      "learning_rate": 4.435981138919116e-06,
      "loss": 35.1409,
      "step": 4300
    },
    {
      "epoch": 2.394035049526505,
      "grad_norm": 46.18009948730469,
      "learning_rate": 4.073268044976424e-06,
      "loss": 35.195,
      "step": 4400
    },
    {
      "epoch": 2.4484597801240886,
      "grad_norm": 54.1904182434082,
      "learning_rate": 3.7141820819731596e-06,
      "loss": 35.9711,
      "step": 4500
    },
    {
      "epoch": 2.4484597801240886,
      "eval_loss": 3.5209739208221436,
      "eval_runtime": 10.5961,
      "eval_samples_per_second": 365.133,
      "eval_steps_per_second": 45.677,
      "step": 4500
    },
    {
      "epoch": 2.502884510721672,
      "grad_norm": 60.48249053955078,
      "learning_rate": 3.351468988030468e-06,
      "loss": 35.0012,
      "step": 4600
    },
    {
      "epoch": 2.5573092413192553,
      "grad_norm": 43.0679817199707,
      "learning_rate": 2.988755894087777e-06,
      "loss": 35.5391,
      "step": 4700
    },
    {
      "epoch": 2.611733971916839,
      "grad_norm": 68.75912475585938,
      "learning_rate": 2.6260428001450855e-06,
      "loss": 35.2277,
      "step": 4800
    },
    {
      "epoch": 2.6661587025144224,
      "grad_norm": 49.52320861816406,
      "learning_rate": 2.263329706202394e-06,
      "loss": 35.2728,
      "step": 4900
    },
    {
      "epoch": 2.7205834331120062,
      "grad_norm": 43.82990646362305,
      "learning_rate": 1.9006166122597028e-06,
      "loss": 35.6176,
      "step": 5000
    },
    {
      "epoch": 2.7205834331120062,
      "eval_loss": 3.513644218444824,
      "eval_runtime": 10.6047,
      "eval_samples_per_second": 364.838,
      "eval_steps_per_second": 45.64,
      "step": 5000
    },
    {
      "epoch": 2.7750081637095896,
      "grad_norm": 77.57071685791016,
      "learning_rate": 1.5379035183170114e-06,
      "loss": 35.73,
      "step": 5100
    },
    {
      "epoch": 2.829432894307173,
      "grad_norm": 51.29985809326172,
      "learning_rate": 1.178817555313747e-06,
      "loss": 35.0271,
      "step": 5200
    },
    {
      "epoch": 2.8838576249047567,
      "grad_norm": 54.83474349975586,
      "learning_rate": 8.161044613710556e-07,
      "loss": 35.8013,
      "step": 5300
    },
    {
      "epoch": 2.9382823555023405,
      "grad_norm": 59.19364929199219,
      "learning_rate": 4.5339136742836425e-07,
      "loss": 34.8807,
      "step": 5400
    },
    {
      "epoch": 2.992707086099924,
      "grad_norm": 44.86369705200195,
      "learning_rate": 9.067827348567283e-08,
      "loss": 35.3996,
      "step": 5500
    },
    {
      "epoch": 2.992707086099924,
      "eval_loss": 3.508282423019409,
      "eval_runtime": 10.5968,
      "eval_samples_per_second": 365.11,
      "eval_steps_per_second": 45.674,
      "step": 5500
    }
  ],
  "logging_steps": 100,
  "max_steps": 5514,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.113440916940444e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
